{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V5E1",
      "mount_file_id": "1msBWZK6X99kEa11Mw0XJXRhf2DIr6gVz",
      "authorship_tag": "ABX9TyMd1S5ROdO0bjLqGwKMiiLD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Luly7/RT/blob/main/CNN_RT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SMILES to CNN model for Retention Time Prediction"
      ],
      "metadata": {
        "id": "upBdXILrJLmz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WxG0S682IWyl",
        "outputId": "df6dc21e-10d5-49ba-d4a9-b427564ca058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cpu)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.11/dist-packages (2022.9.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.23.5)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.14.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: numpy==1.23.5 in /usr/local/lib/python3.11/dist-packages (1.23.5)\n",
            "Epoch 1: Train Loss = 60358.0840\n",
            "Epoch 2: Train Loss = 37471.7269\n",
            "Epoch 3: Train Loss = 34918.0839\n",
            "Epoch 4: Train Loss = 33607.6936\n",
            "Epoch 5: Train Loss = 32611.6877\n",
            "Epoch 6: Train Loss = 31746.4482\n",
            "Epoch 7: Train Loss = 30688.1310\n",
            "Epoch 8: Train Loss = 29210.2449\n",
            "Epoch 9: Train Loss = 27993.0444\n",
            "Epoch 10: Train Loss = 26917.2859\n",
            "\n",
            "Test RMSE: 162.17\n",
            "Test MAE: 119.02\n",
            "Test R² Score: 0.3803\n",
            "\n",
            "Predictions saved to CSV ✅\n"
          ]
        }
      ],
      "source": [
        "# 1. Install if missing\n",
        "!pip install torch torchvision pandas scikit-learn rdkit-pypi\n",
        "!pip install numpy==1.23.5\n",
        "# 2. Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from rdkit import Chem\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "# 3. Load your data\n",
        "csv_path = '/content/drive/MyDrive/CS6480/output_rt_fixed_smiles_unique.csv'  # <-- change if needed\n",
        "data = pd.read_csv(csv_path)\n",
        "\n",
        "# 4. Build SMILES to integer encoding\n",
        "# Simple atom-level encoding (you can make it smarter later)\n",
        "def smiles_to_int(smiles, max_len=100):\n",
        "    vocab = {ch: idx+1 for idx, ch in enumerate(sorted(set(''.join(smiles))))}  # Unique characters\n",
        "    encoded = [vocab.get(ch, 0) for ch in smiles]\n",
        "    padded = encoded + [0] * (max_len - len(encoded))\n",
        "    return padded[:max_len]\n",
        "\n",
        "X = np.array([smiles_to_int(smi) for smi in data['fixed_smiles']])\n",
        "y = np.array(data['rt'], dtype=np.float32)\n",
        "\n",
        "# 5. Create Dataset and DataLoader\n",
        "class SmilesDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = torch.tensor(X, dtype=torch.long)\n",
        "        self.y = torch.tensor(y, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "dataset = SmilesDataset(X, y)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# 6. Define CNN Model\n",
        "class CNN_RT(nn.Module):\n",
        "    def __init__(self, vocab_size, emb_dim=32):\n",
        "        super(CNN_RT, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size + 1, emb_dim, padding_idx=0)\n",
        "        self.conv1 = nn.Conv1d(emb_dim, 64, kernel_size=5, padding=2)\n",
        "        self.conv2 = nn.Conv1d(64, 128, kernel_size=5, padding=2)\n",
        "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
        "        self.fc = nn.Linear(128, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.embedding(x)  # (batch, seq_len, emb_dim)\n",
        "        x = x.permute(0, 2, 1)  # (batch, emb_dim, seq_len) for Conv1d\n",
        "        x = torch.relu(self.conv1(x))\n",
        "        x = torch.relu(self.conv2(x))\n",
        "        x = self.pool(x).squeeze(-1)\n",
        "        out = self.fc(x)\n",
        "        return out.view(-1)\n",
        "\n",
        "# 7. Setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "vocab_size = max([max(seq) for seq in X])\n",
        "model = CNN_RT(vocab_size).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "loss_fn = nn.MSELoss()\n",
        "\n",
        "# 8. Training loop\n",
        "n_epochs = 10\n",
        "for epoch in range(n_epochs):\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    for inputs, targets in train_loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(inputs)\n",
        "        loss = loss_fn(preds, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss / len(train_loader):.4f}\")\n",
        "\n",
        "# 9. Evaluation\n",
        "model.eval()\n",
        "preds = []\n",
        "trues = []\n",
        "with torch.no_grad():\n",
        "    for inputs, targets in test_loader:\n",
        "        inputs = inputs.to(device)\n",
        "        preds.append(model(inputs).cpu().numpy())\n",
        "        trues.append(targets.numpy())\n",
        "\n",
        "preds = np.concatenate(preds)\n",
        "trues = np.concatenate(trues)\n",
        "\n",
        "rmse = np.sqrt(mean_squared_error(trues, preds))\n",
        "mae = mean_absolute_error(trues, preds)\n",
        "r2 = r2_score(trues, preds)\n",
        "\n",
        "print(f\"\\nTest RMSE: {rmse:.2f}\")\n",
        "print(f\"Test MAE: {mae:.2f}\")\n",
        "print(f\"Test R² Score: {r2:.4f}\")\n",
        "\n",
        "# 10. Save results\n",
        "results_df = pd.DataFrame({'True_RT': trues, 'Predicted_RT': preds})\n",
        "results_df.to_csv('/content/drive/MyDrive/CS6480/CNN/retention_time_predictions_cnn.csv', index=False)\n",
        "print(\"\\nPredictions saved to CSV ✅\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "44oHfuXjJKUA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "k7-JA79bJJJe"
      }
    }
  ]
}